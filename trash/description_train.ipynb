{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import ultraprint.common as p\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import librosa.display\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:/Downloads/MusicBench'\n",
    "file_dir = 'D:/Downloads/MusicBench/MusicBench/datashare'\n",
    "model_dir = 'models/ranit/description'\n",
    "model_name = model_dir+'/ranit_description_embedder_v1'\n",
    "\n",
    "#create directories if they don't exist\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ranit Bhowmick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from txtai.embeddings import Embeddings\n",
    "\n",
    "# Create an embeddings index\n",
    "embeddings = Embeddings({\"path\": \"sentence-transformers/paraphrase-MiniLM-L6-v2\"})\n",
    "\n",
    "def transform(sentence):\n",
    "    if type(sentence) == str:\n",
    "        sentence = [sentence]\n",
    "    return embeddings.batchtransform(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Loading data from cache\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(data_dir + '/train_data.pt'):\n",
    "    p.green('Loading data from cache')\n",
    "    data = torch.load(data_dir + '/train_data.pt')\n",
    "else:\n",
    "    # load \"MusicBench_train.json\"\n",
    "    p.red('File not found, Loading data from file')\n",
    "    data = []\n",
    "    with open(data_dir + '/MusicBench_train.json', 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in tqdm(lines, desc=\"Loading data\"):\n",
    "            temp_json = json.loads(line.strip())\n",
    "            data.append({\n",
    "                'location': file_dir+\"/\"+temp_json['location'],\n",
    "                'vector': transform(temp_json['main_caption'])\n",
    "            })\n",
    "    # save the data\n",
    "    torch.save(data, data_dir + '/train_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranit Bhowmick\\AppData\\Local\\Temp\\ipykernel_13148\\1416850965.py:26: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  tensor_y = torch.tensor(y, dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['D:/Downloads/MusicBench/MusicBench/datashare/data_aug2/tv14XEQcY0c_3.wav',\n",
       "  'D:/Downloads/MusicBench/MusicBench/datashare/data_aug2/cmJj7SxQEp8_7.wav',\n",
       "  'D:/Downloads/MusicBench/MusicBench/datashare/data_aug2/5-tx4Fgqetc_8.wav',\n",
       "  'D:/Downloads/MusicBench/MusicBench/datashare/data_aug2/WK-gdfCurCg_7.wav',\n",
       "  'D:/Downloads/MusicBench/MusicBench/datashare/data_aug2/AAP5pAB-4jM_5.wav'],\n",
       " tensor([[-0.0498, -0.0006, -0.1066,  ...,  0.0109, -0.0298,  0.0252],\n",
       "         [-0.0587,  0.0015, -0.0023,  ...,  0.0860,  0.0409,  0.0053],\n",
       "         [ 0.0565, -0.0086, -0.0462,  ...,  0.0653,  0.0678, -0.0262],\n",
       "         [-0.0317,  0.0066, -0.0134,  ...,  0.0813, -0.0615, -0.0531],\n",
       "         [ 0.0128, -0.0364,  0.0080,  ...,  0.0727,  0.0246,  0.0222]],\n",
       "        device='cuda:0'),\n",
       " tensor([ 1., -1.,  1.,  1.,  1.], device='cuda:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(n=5):\n",
    "    #get random files from withing each folder and for each also store the array containing the expected output\n",
    "    x = []\n",
    "    y = []\n",
    "    labels = []\n",
    "    for i in range(n):\n",
    "        random_data = random.choice(data)\n",
    "        random_integer = random.randint(0, 1)\n",
    "\n",
    "        if random_integer == 0:\n",
    "            x.append(random_data['location'])\n",
    "            y.append(random_data['vector'][0])\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            another_random_data = random.choice(data)\n",
    "            # make sure that the two vectors are not the same\n",
    "            while another_random_data['location'] == random_data['location']:\n",
    "                another_random_data = random.choice(data)\n",
    "\n",
    "            x.append(random_data['location'])\n",
    "            y.append(another_random_data['vector'][0])\n",
    "            # calculate the cosine similarity between the two vectors\n",
    "            labels.append(-1)\n",
    "\n",
    "    #turn y into a tensor\n",
    "    tensor_y = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32, device=device)\n",
    "\n",
    "    return x, tensor_y, labels\n",
    "\n",
    "get_batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desc_model import DescriptionEmbedder\n",
    "\n",
    "\n",
    "def contrastive_loss(output1, output2, label, margin=1.0):\n",
    "    # Compute Euclidean distance\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    # Adjust label: map 1 -> 0 (similar), -1 -> 1 (dissimilar)\n",
    "    label = (1 - label) / 2  # 1 -> 0, -1 -> 1\n",
    "    # Contrastive loss formula\n",
    "    loss = torch.mean(\n",
    "        (1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "        label * torch.pow(torch.clamp(margin - euclidean_distance, min=0.0), 2)\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "def train(epochs=100, batch_size=5, learning_rate=0.001, weight_decay=1e-2):\n",
    "    \n",
    "    # Initialize model and optimizer\n",
    "    # Model outputs 10 classes\n",
    "    model = DescriptionEmbedder(device=device)\n",
    "    model.load(model_name)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # Switched to AdamW\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        epoch_losses = []\n",
    "        \n",
    "        # Create progress bar for each epoch\n",
    "        with tqdm(range(100), desc=f'Epoch {epoch+1}/{epochs}') as pbar:\n",
    "            \n",
    "            for _ in pbar:\n",
    "                try:\n",
    "                    # Get batch\n",
    "                    audio_paths, vectors, labels = get_batch(batch_size)\n",
    "\n",
    "                    # continue if batch size is less than expected\n",
    "                    if len(audio_paths) != batch_size:\n",
    "                        p.yellow(f'Batch size mismatch, skipping batch')\n",
    "                        continue\n",
    "\n",
    "                    # Forward pass\n",
    "                    output_vectors = model(audio_paths)\n",
    "\n",
    "                    # check if length of probabilities is equal to length of labels\n",
    "                    if len(output_vectors) != len(vectors):\n",
    "                        p.yellow(f'Length mismatch between probabilities and labels, skipping batch')\n",
    "                        continue\n",
    "\n",
    "                    # Check gradient\n",
    "                    if not output_vectors.requires_grad:\n",
    "                        p.yellow(\"Warning: probabilities lost gradient tracking\")\n",
    "                        continue\n",
    "                \n",
    "                    # Calculate loss\n",
    "                    loss = contrastive_loss(output_vectors, vectors, labels)\n",
    "                    \n",
    "                    if not loss.requires_grad:\n",
    "                        p.yellow(\"Warning: loss lost gradient tracking\")\n",
    "                        continue\n",
    "\n",
    "                    # Backward pass\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # Track progress\n",
    "                    epoch_losses.append(loss.item())\n",
    "\n",
    "                    pbar.set_postfix({'loss': np.mean(epoch_losses)})\n",
    "\n",
    "                except Exception as e:\n",
    "                    #print full stack trace\n",
    "                    p.red(e)\n",
    "                    continue\n",
    "        \n",
    "        # Save model checkpoint every epochs\n",
    "        model.save(model_name)\n",
    "        p.green(f'\\nCheckpoint saved at epoch {epoch+1}')\n",
    "        p.blue(f'Epoch {epoch+1} average loss: {np.mean(epoch_losses):.4f}')\n",
    "\n",
    "# Start training\n",
    "if __name__ == \"__main__\":\n",
    "    train(batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio paths: ['D:/Downloads/MusicBench/MusicBench/datashare/data/DdxW_JziHTA.wav']\n",
      "Labels shape: torch.Size([1, 384])\n",
      "Labels: tensor([-1.], device='cuda:0')\n",
      "Cosine similarity: 0.7931150197982788\n",
      "Output vectors shape: tensor([[-6.9185e-03, -9.2591e-03, -1.8954e-03, -9.7962e-02, -9.3861e-02,\n",
      "          4.4947e-02,  6.2599e-02, -7.5256e-02,  4.9556e-02,  1.2668e-02,\n",
      "          3.2759e-02,  1.9892e-02,  2.1348e-02, -6.8725e-02,  5.8483e-02,\n",
      "          4.9880e-02,  8.6015e-02,  6.9803e-02,  2.0605e-02, -2.0048e-02,\n",
      "         -1.7037e-03,  8.4226e-02, -2.2626e-02, -3.5646e-02, -6.0768e-02,\n",
      "         -3.3919e-02, -2.3313e-02,  6.4171e-02,  3.4541e-02, -3.5094e-02,\n",
      "          4.0316e-02,  1.0456e-01,  7.3339e-02, -4.0929e-02, -9.7383e-02,\n",
      "          1.0786e-01, -6.3471e-02, -2.6066e-02, -1.0236e-01,  1.6811e-02,\n",
      "         -3.1472e-02,  1.0054e-02, -1.1470e-03, -1.5678e-02, -4.3293e-02,\n",
      "         -6.4183e-03, -5.7657e-02, -1.4711e-02,  3.5724e-02,  4.1702e-02,\n",
      "         -8.7406e-02, -4.5196e-02,  4.1524e-02, -1.2530e-03, -3.4045e-02,\n",
      "         -5.0430e-02,  8.0558e-03,  1.6555e-01, -1.2110e-02,  2.9762e-02,\n",
      "          9.4668e-03,  9.1264e-03, -3.5489e-02, -5.0942e-02,  2.1474e-02,\n",
      "         -5.5525e-03, -2.3134e-03, -1.3114e-02, -6.1192e-02,  5.6626e-02,\n",
      "          2.5336e-03, -1.2309e-02, -1.6801e-02, -8.2043e-02,  2.4282e-02,\n",
      "         -1.4779e-03, -5.4066e-02, -3.1389e-02, -1.3949e-02, -4.1894e-02,\n",
      "          8.7479e-02, -1.2133e-01, -8.2224e-02, -1.0596e-01, -2.6031e-03,\n",
      "          3.4472e-03,  2.2600e-02,  3.1171e-02, -5.1400e-03, -1.3259e-02,\n",
      "         -1.4225e-01,  3.1243e-02, -6.5837e-02, -4.0464e-02,  9.1597e-02,\n",
      "          3.7188e-02,  1.2133e-03, -1.2201e-02, -1.2784e-02,  1.3204e-02,\n",
      "          8.2439e-02,  6.3317e-02, -5.5212e-02,  4.0552e-02,  1.5385e-02,\n",
      "         -7.1401e-02,  5.2538e-02,  7.3440e-02,  1.8299e-02, -6.6644e-02,\n",
      "         -1.0132e-03,  2.0402e-05,  3.4065e-03, -1.6433e-02,  6.0371e-03,\n",
      "          1.2084e-02,  2.2034e-02, -3.9605e-02,  7.0872e-03, -2.0791e-02,\n",
      "          6.7437e-02, -1.1280e-01, -1.0587e-01, -1.0636e-02, -1.3239e-02,\n",
      "          2.6978e-02, -3.6752e-02, -3.5262e-03,  2.4814e-02, -1.1230e-02,\n",
      "          2.2499e-02, -9.3220e-03,  1.3469e-01, -1.6366e-02, -6.8773e-02,\n",
      "          2.2879e-02, -2.3997e-03,  1.0554e-01, -5.3642e-03, -3.6453e-02,\n",
      "         -1.1918e-02,  6.3598e-02, -1.3075e-02, -8.1490e-02, -4.9997e-02,\n",
      "         -3.2820e-02, -5.9197e-02, -5.3986e-02,  1.1709e-02,  2.9417e-02,\n",
      "         -2.4836e-02, -4.3340e-02,  1.9935e-02,  1.5254e-02,  1.2765e-01,\n",
      "          3.5755e-02,  4.3522e-02, -3.0908e-03,  1.5140e-02,  3.5201e-02,\n",
      "         -1.2450e-03, -2.7549e-02,  8.7456e-03,  2.5931e-02, -2.3934e-02,\n",
      "          3.9425e-02, -1.0675e-02,  1.6680e-02, -2.2834e-02, -2.9303e-02,\n",
      "         -1.1530e-01, -6.9066e-03, -2.6095e-03,  6.3780e-03, -3.8030e-02,\n",
      "          1.7680e-02,  3.4289e-02,  3.9106e-02,  2.7494e-02,  6.4953e-02,\n",
      "          1.8637e-02,  5.3443e-02,  7.2288e-02,  8.4753e-02, -5.6976e-02,\n",
      "          6.2744e-02,  1.2124e-02,  4.5439e-02, -2.2808e-03, -1.3806e-02,\n",
      "          3.4748e-02, -7.0046e-02, -4.2718e-03,  7.9616e-05, -3.4412e-02,\n",
      "         -2.3318e-02,  4.2199e-02, -2.3247e-02,  3.1029e-02,  7.0585e-03,\n",
      "         -2.9211e-02, -3.7623e-03,  4.3355e-02, -4.9017e-03,  3.5817e-03,\n",
      "         -2.2438e-02,  5.9947e-02, -1.5900e-02, -5.1193e-03,  4.8302e-02,\n",
      "         -5.8414e-02, -9.8230e-03,  4.6344e-02,  4.5091e-02,  4.1938e-02,\n",
      "         -1.1541e-01, -5.2238e-02, -3.8269e-02, -8.2645e-02,  6.9635e-02,\n",
      "          1.1307e-02, -7.7537e-02,  1.5272e-02, -6.7913e-02,  5.9169e-02,\n",
      "          6.7984e-02, -5.3696e-02,  7.0467e-02,  4.0084e-02,  4.6622e-02,\n",
      "          3.9966e-02,  8.2538e-02,  1.0692e-02,  1.6575e-02,  3.8364e-03,\n",
      "         -3.9123e-02,  4.7407e-03, -3.8146e-02, -3.0442e-02, -5.8849e-02,\n",
      "         -3.4628e-02,  5.5620e-03,  9.7654e-02,  5.7449e-02, -4.4861e-02,\n",
      "         -7.5099e-02,  3.7242e-03,  9.8406e-02, -5.9631e-03, -3.8649e-02,\n",
      "         -2.1535e-03,  9.7447e-02, -6.4824e-02,  3.0842e-02,  3.3370e-02,\n",
      "          5.0458e-02, -3.1799e-02, -8.8769e-02, -4.2388e-02,  1.9222e-02,\n",
      "          5.9675e-02,  2.2541e-02, -1.4375e-02, -3.2585e-02, -2.8633e-02,\n",
      "          6.6905e-02,  7.7446e-02,  9.8302e-02, -4.1736e-02,  1.3074e-02,\n",
      "         -1.7020e-02,  6.0383e-02, -2.0955e-02, -6.5601e-02,  4.5134e-02,\n",
      "         -9.9654e-03,  9.3592e-03, -3.8644e-02, -4.6577e-02,  5.4821e-02,\n",
      "         -3.5318e-02, -9.9498e-02,  1.3371e-03,  9.5551e-02, -6.9452e-03,\n",
      "          4.1198e-02, -1.8500e-02, -1.2986e-01,  9.1045e-02,  4.5813e-02,\n",
      "          7.1859e-02,  6.2928e-02,  4.3324e-03,  8.3663e-02, -2.9598e-02,\n",
      "          1.5819e-02, -2.6854e-02,  6.9582e-02, -1.7147e-02, -1.0418e-02,\n",
      "          1.9681e-02, -5.4125e-02,  2.4839e-02, -3.2121e-02,  3.2048e-02,\n",
      "         -8.1400e-03, -6.7056e-02, -2.9037e-02, -8.4346e-03,  8.6649e-03,\n",
      "         -2.2181e-02,  9.1026e-02, -5.3452e-02,  8.7612e-02,  6.4403e-03,\n",
      "          6.3705e-02, -3.0287e-02,  4.8142e-02,  2.9692e-02,  7.3232e-03,\n",
      "         -6.6742e-02, -6.9136e-02, -4.8484e-02, -3.7734e-02,  2.8649e-02,\n",
      "          3.5615e-02,  5.2524e-02, -1.7464e-01, -6.0181e-03, -1.3373e-02,\n",
      "          4.3797e-02, -8.2091e-02, -1.4584e-02,  8.1961e-02, -1.1061e-02,\n",
      "          4.0401e-02, -2.2278e-02,  9.7537e-03, -2.2986e-02, -6.9716e-02,\n",
      "          1.4195e-02, -2.4690e-02,  1.0895e-01, -6.0883e-02, -3.0120e-02,\n",
      "          5.5747e-03, -6.0487e-02,  4.1281e-02, -8.4394e-02, -6.5413e-02,\n",
      "         -1.6218e-02,  5.9881e-02,  7.0048e-03, -6.4523e-02, -6.7561e-02,\n",
      "         -9.0938e-03, -6.1046e-02, -5.4540e-03, -2.9349e-02, -5.0992e-03,\n",
      "          3.1451e-03,  1.9695e-02, -1.1234e-02,  6.1606e-02, -8.5616e-02,\n",
      "         -1.1673e-02,  4.6028e-02, -2.8234e-02,  6.6662e-03,  8.2802e-02,\n",
      "          3.2098e-02, -3.0209e-02,  2.6875e-02,  3.8381e-02,  4.9979e-02,\n",
      "          2.1916e-02,  2.0138e-02,  1.2364e-01, -4.0555e-03,  1.4636e-02,\n",
      "          1.0109e-02,  8.5461e-02,  3.7083e-03,  1.2400e-03]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_class, model_path, device='cuda'):\n",
    "    model = model_class(device=device)\n",
    "    model.load(model_path)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load model\n",
    "model = load_model(DescriptionEmbedder, model_name)\n",
    "\n",
    "# Get batch (assuming get_batch is implemented elsewhere)\n",
    "audio_paths, vectors, labels = get_batch(n=1)\n",
    "print(\"Audio paths:\", audio_paths)\n",
    "print(\"Labels shape:\", vectors.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_vectors = model(audio_paths)\n",
    "\n",
    "print(\"Labels:\", labels)\n",
    "\n",
    "#compute cosine similarity output_vectors, vectors\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output = cos(output_vectors, vectors)\n",
    "print(\"Cosine similarity:\", output.item())\n",
    "\n",
    "print(\"Output vectors shape:\", output_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
